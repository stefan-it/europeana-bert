{
    "seeds": [1],
    "batch_sizes": [16, 8],
    "hf_model": "xlm-roberta-base",
    "context_size": 0,
    "epochs": [1,5,10],
    "learning_rates": [1e-5, 3e-5, 5e-5],
    "data_folder": "./data",
    "train_file": "enp_DE.lft.mr.tok.train.bio",
    "dev_file": "enp_DE.lft.mr.tok.dev.bio",
    "test_file": "enp_DE.lft.mr.tok.test.bio",
    "task_name": "lft",
    "cuda": "0"
}

